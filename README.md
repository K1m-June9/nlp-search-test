# Korean Text Summarization
> PublicInsight 프로젝트에 적용할 최적의 한국어 텍스트 요약 모델을 선정하고, 실제 환경의 제약조건(장문, PDF)을 해결하기 위한 요약 엔진 개발 연습

## 목표
PublicInsight 서비스의 핵심 기능인 '문서 요약'을 위해, 현재 사용 가능한 여러 한국어 NLP 모델의 성능을 직접 비교하고 평가합니다.
최종적으로는 벤치마킹 결과를 바탕으로 최적의 모델을 선정하고, 이를 기반으로 다양한 길이와 형식의 문서를 처리할 수 있는 실용적인 요약 엔진 프로토타입을 개발하는 것을 목표로 합니다.

## **벤치마킹 및 분석 과정**

최적의 모델을 선정하기 위해, 정량적 지표뿐만 아니라 실제 사용자가 느끼는 요약문의 품질(가독성, 핵심 내용 포함 여부)을 중심으로 한 **정성적 평가**에 비중을 두어 테스트를 진행

### **후보 모델 탐색 및 최종 후보 선정 (Model Exploration & Finalist Selection)**
*   **초기 후보 모델**: `BERT`, `T5`, `Pegasus`, `BART`, `XLNet` 등 다양한 계열의 사전 학습 모델을 초기 후보군으로 설정
*   **최종 후보 선정**: 초기 기술 검증 단계에서 구현 용이성과 안정적인 실행 가능성을 기준으로 **`BART`**와 **`T5`**를 최종 비교 후보로 선정하여 심층적인 성능 분석을 진행
*   **주요 결과**:
    <img width="3207" height="1767" alt="model_comparison_heatmap" src="https://github.com/user-attachments/assets/fd7126c2-f653-4fc9-bde7-13bcc86d5523" />


### **핵심 키워드 추출 방법론 검토**
요약문의 품질과 더불어 문서의 핵심 주제를 파악하기 위한 키워드 추출 능력도 함께 검토
당초 `KeyBERT`와 같은 최신 딥러닝 기반 모델을 중심으로 테스트를 진행했으나, GPU 부재 등 홈 서버 환경의 리소스 제약을 고려하여 최종적으로는 **`TF-IDF`**와 같은 전통적인 통계 기반 방법론의 실용성을 확인하는 방향으로 전환
*   **주요 결과**:
    <img width="3228" height="1766" alt="keyword_extraction_heatmap" src="https://github.com/user-attachments/assets/5a8f50e7-6686-4e80-ac24-91326df58cad" />


### **하이퍼파라미터 탐색**
최종 후보 모델의 성능을 미세 조정하기 위해, `num_beams`, `length_penalty`, `repetition_penalty` 등 요약문 생성에 영향을 미치는 주요 하이퍼파라미터들을 여러 조합으로 테스트하며 결과물의 변화를 관찰
*   **주요 결과**:
    <img width="1226" height="920" alt="스크린샷 2025-11-09 12 15 33" src="https://github.com/user-attachments/assets/8087ec18-2fa8-4117-9c52-fc240faabf18" />
    <img width="1227" height="814" alt="스크린샷 2025-10-24 13 53 17" src="https://github.com/user-attachments/assets/de3c70e9-68b7-4d87-95b9-8be23929be86" />


## **최적 모델 선정**
일련의 정성적, 정량적 평가를 종합한 결과, **KoBART (`digit82/kobart-summarization`)** 모델을 PublicInsight 프로젝트의 최종 요약 모델로 선정

*   **선정 이유**: KoBART는 T5 대비 문장의 자연스러움과 가독성 측면에서 전반적으로 우위를 보였으며, 특히 원문의 핵심 맥락을 누락하지 않으면서도 간결하게 요약하는 능력에서 가장 높은 평가를 받음

## **최종 개발 결과물: 요약 엔진**
벤치마킹 결과를 바탕으로, 실제 서비스 환경에서 사용 가능한 요약 엔진 클래스 TextSummarizer를 개발했습니다.

*   **주요 기능**:
    *   계층적 요약: 긴 텍스트를 문장 단위로 분할하여 1차 요약하고, 그 요약문들을 다시 입력으로 사용하여 최종 요약문을 생성하는 '분할 정복' 방식을 `hierarchical_summarize` 메서드에 구현하여 모델의 입력 길이 한계를 극복
    *   다중 포맷 지원: `summarize` 메인 메서드를 통해 일반 텍스트뿐만 아니라 '.pdf' 파일 경로도 직접 입력받아 내부적으로 텍스트를 추출하고 요약 프로세스를 수행
    *   자동 디바이스 설정: 사용자 환경에 맞춰 `CUDA` 가용 여부를 자동으로 감지하고, 최적의 디바이스(GPU/CPU)에 모델을 할당하여 편의성과 실행 안정성을 높임

